{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated spam filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data, look around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data directory of the repository, you should see a file called `SMSSpamCollection`, about 0.5MB in size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages**. This line of code puts each line of SMS message into a list as a list element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.rstrip() for line in open('../data/SMSSpamCollection.txt')]\n",
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of texts is also sometimes called \"corpus\". Let's print the first ten messages in this SMS corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message_no, message in enumerate(messages[:10]):\n",
    "    print(message_no, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is a [TSV](http://en.wikipedia.org/wiki/Tab-separated_values) (\"tab separated values\") file, where the first column is a label saying whether the given message is a normal message (\"ham\") or \"spam\". The second column is the message itself.\n",
    "\n",
    "This corpus will be our labeled training set. Using these ham/spam examples, we'll **train a machine learning model to learn to discriminate between ham/spam automatically**. Then, with a trained model, we'll be able to **classify arbitrary unlabeled messages** as ham or spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://radimrehurek.com/data_science_python/plot_ML_flow_chart_11.png)](http://www.astroml.org/sklearn_tutorial/general_concepts.html#supervised-learning-model-fit-x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of parsing TSV (or CSV, or Excel...) files by hand, we can use Python's `pandas` library to do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pandas.read_csv('../data/SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `pandas`, we can also view aggregate statistics easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "count_Class = pd.value_counts(messages['label'], sort = True)\n",
    "count_Class.plot(kind='bar', color=[\"red\", \"yellow\"])\n",
    "plt.title('Bar Chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "count_Class = pd.value_counts(messages['label'], sort = True)\n",
    "count_Class.plot(kind='pie', autopct='%1.0f%%')\n",
    "plt.title('Pie Chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat pacakge in Python is the collections package and the Counter function within it.  It tallies up data very quickly, see [documentation](https://docs.python.org/2/library/collections.html).\n",
    "\n",
    "Note:  The code below is for exemplifying how we go from text messages to the features, the individual words of the messages.  The code is complicated, but here so you can see how this may be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data = messages\n",
    "#This code splits the \n",
    "\n",
    "count1 = Counter(\" \".join(data[data['label']=='ham'][\"message\"]).split()).most_common(20)\n",
    "df1 = pd.DataFrame.from_dict(count1)\n",
    "df1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
    "count2 = Counter(\" \".join(data[data['label']=='spam'][\"message\"]).split()).most_common(20)\n",
    "df2 = pd.DataFrame.from_dict(count2)\n",
    "df2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(legend = False, color = 'orange')\n",
    "y_pos = np.arange(len(df2[\"words in spam\"]))\n",
    "plt.xticks(y_pos, df2[\"words in spam\"])\n",
    "plt.title('More frequent words in spam messages')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we represent text as data that can be modeled?  \n",
    "\n",
    "Let's take a close look at a very simple example of how we would represent a training and test dataset of SMS messages for machine learning.  Rather than the code above, we can use tools, like CountVectorizer, to convert text into its \"word\" features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a count of each word in the message as a feature.  There is a nice easy way to do this [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me...PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train_dtm = vect.fit_transform(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(simple_train_dtm.toarray(), columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test = [\"please dont call me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test_dtm = vect.transform(simple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(simple_test_dtm.toarray(), columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "* vect.fit(train) learns the vocabulary of the training data.\n",
    "* vect.transform(train) uses the fitted vocabulary to build a document-term matrix from the training data. Or just vect.fit_transform(train) to combine the two steps into one.\n",
    "* vect.transform(test) uses the fitted vocabulary to build a document-term matrix from the testing data. Note that it ignores tokens it hasn't seen before, this is reasonable due to the fact that the word does not exist in the training data, thus the model doesn't know anything about the relationship between the word and the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now back to the SMS larger dataset - building a model and testing a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll remember from our last lecture introducing machine learning that you need some requirements for machine learning:  First, we need to determine your X and y datasets.  We need to first define what we want to predict, and that is whether a message is ham or spam.  to this, we will transform the variable spam/non-spam into binary variables.  Next, we'll split our data into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head()\n",
    "\n",
    "messages['label_no'] = messages['label'].map({'spam':1,'ham':0})\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = messages['message']\n",
    "y = messages['label_no']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first metric we are going to discuss is, perhaps, the simplest one, the accuracy. It answers the question:\n",
    "“How often is the classifier correct?”\n",
    "It can be obtained simply using the following formulae:\n",
    "\n",
    "sklearn provides the function accuracy_score to obtain the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our spam filtering algorithm has an accuracy of 99%, that is, for each 100 emails it classified, 99 were correctly classified as spam or not spam.\n",
    "\n",
    "Does this mean that our algorithm has an excellent performance? Suppose that our dataset had 99% real emails and 1% spam and that we built a classifier that predicted that all emails were real. Then, this algorithm would be 99% accurate, but horrible at classifying spam! It is important to have other ways to measure the performance of the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is another metric that is often used to measure the performance of a classification algorithm. \n",
    "\n",
    "For are example, the confusion matrix will be of the following form:\n",
    "\n",
    "|                    | Predicted: HAM SMS | Predicted: SPAM SMS |\n",
    "|--------------------|-----------------------|-----------------------|\n",
    "| Actual: HAM SMS | True Positives (TP)   | False Negative (FN)  |\n",
    "| Actual: SPAM SMS | False Positive (FP)  | True Negatives (TN)   |\n",
    "\n",
    "The predicted classes are represented in the columns of the matrix, whereas the actual classes are in the rows of the matrix. We then have four cases:\n",
    "\n",
    "* True positives (TP): the cases for which the classifier predicted ‘ham’ and the texts were actually ham.\n",
    "* True negatives (TN): the cases for which the classifier predicted ‘not ham’ and the texts were actually 'not ham' or spam.\n",
    "* False positives (FP): the cases for which the classifier predicted ‘ham’ but the texts were actually 'spam'.\n",
    "* False negatives (FN): the cases for which the classifier predicted ‘spam’ but the texts were actually real.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "cmdf = pd.DataFrame(cm, index = ['ham','spam'], columns = ['ham', 'spam'])\n",
    "print(cmdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the confusion matrix, we see that the Naive Bayes classifier got the following results:\n",
    "\n",
    "Out of the 1206 + 6 = 1212 actual instances of 'ham' (not spam), it predicted correctly 1206 of them;\n",
    "Out of the 182 actual instances of spam, it predicted correctly 172 of them.\n",
    "\n",
    "\n",
    "Note that the accuracy may be obtained from the confusion matrix, as the sum of the diagonal divided by the sum of all matrix entries.\n",
    "\n",
    "Accuracy = (TP + TN) / (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1206 + 172) / (1206 + 6 + 10 + 172)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the accuracy, there are several other performance measures which can be computed from the confusion matrix. Some of the main ones are obtained using the function classification_report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_class, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "“When it predicts the positive result, how often is it correct?”\n",
    "This is obtained by using the following formulae:\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Precision is usually used when the goal is to limit the number of false positives (FP). For example, this would be the metric to focus on if our goal with the spam filtering algorithm is to minimize the number of reals emails that are classified as spam.\n",
    "\n",
    "#### Recall\n",
    "\n",
    "“When it is actually the positive result, how often does it predict correctly?”\n",
    "This is obtained by using the following formulae:\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "Recall is usually used when the goal is to limit the number of false negatives (FN). In our example, that would correspond to minimizing the number of spam emails that are classified as real emails. Recall is also known as “sensitivity” and “true positive rate” (TPR).\n",
    "\n",
    "#### f1-score\n",
    "\n",
    "This is the harmonic mean of precision and recall:\n",
    "\n",
    "f1-score = 2 * precision*recall / (precision + recall)\n",
    "\n",
    "It is useful when you need to take both precision and recall into account. If you try to only optimize recall, your algorithm will predict most examples to belong to the positive class, but that will result in many false positives and, hence, low precision. On the other hand, if you try to optimize precision, your model will predict very few examples as positive results (the ones which highest probability), but recall will be very low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve\n",
    "\n",
    "A more visual way to measure the performance of a binary classifier is the receiver operating characteristic (ROC) curve. It is created by plotting the true positive rate (TPR) (or recall) against the false positive rate (FPR), which we haven’t defined explicitly yet:\n",
    "\n",
    "FP rate = FP / (FP + TN)\n",
    "\n",
    "The question it is trying to answer is:  “When it is actually the negative result, how often does it predict incorrectly?”\n",
    "\n",
    "Let’s see how we can obtain this curve. First, note that our Naive Bayes algorithm isn’t only able to predict if each email is spam or not, but it can also give us the predicted probability for such event. The predicted probability for the test set can be obtained in sklearn with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.15314525e-14 6.05184629e-08 2.43794217e-05 ... 8.04154411e-08\n",
      " 1.00000000e+00 8.21401800e-05]\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:,1]\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predicted probabilities for each email, how do we decide if it is spam based on the values of those probabilities? That is, what is threshold for the probability above which we classify the email as spam?\n",
    "It seems reasonable, at least at first, to take the threshold to be 0.5. The nice thing about the ROC curve is that we can visualize how the performance of the classifier changes as we vary the threshold.\n",
    "First, let’s plot the ROC curve for the case at hand by importing roc_curve from sklearn.metrics, which gives us the TP and FP rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a26fabfd0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([-0.02, 1])\n",
    "plt.ylim([0, 1.02])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this plot, let’s analyse it in steps.\n",
    "\n",
    "Suppose we take the threshold to be 0, that is, all emails are classified as spam. \n",
    "On the one hand, this implies that no spam emails are predicted as real emails and so there are no false negatives — the true positive rate (or recall) is 1. On the other hand, this also means that no real email is classified as real, and thus there are no true negatives — the false positive rate is also 1. This corresponds to the top-right part of the curve.\n",
    "\n",
    "Now suppose that the threshold is 1, that is, no email is classified as spam. Then, there are no true positives (and thus the true positive rate is 0) and no false positives (and thus the false positive rate is 0). This corresponds to the bottom-left of the curve.\n",
    "\n",
    "The rest of the curve corresponds to values of the threshold between 0 and 1, from the top-right to the bottom-left. As you can see, the curve approaches (but does not reach) the corner of the plot where the TP rate is 1 and the FP rate is 0 — that is, no spam emails are classified as real and no real emails are classified as spam. This is the point of perfect classification.\n",
    "\n",
    "The TP rate is the proportion of emails predicted as spam which are actually spam. The FP rate is the proportion of actual real emails which are predicted as spam.\n",
    "\n",
    "If we are in the diagonal line, that means that the proportion of emails predicted as spam which turn out to be actual spam is roughly the same as the proportion of real emails which are predicted as spam. This is as good as random guessing, and a classifier with this performance would be pretty terrible.\n",
    "\n",
    "The above points suggest that the area under the ROC curve (usually denoted by AUC) is a good measure of the performance of the classification algorithm. If it is near 0.5, the classifier is not much better than random guessing, whereas it gets better as the area gets close to 1.\n",
    "\n",
    "We can obtain the AUC by importing roc_auc_score from sklearn.metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856698581946108"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is indeed quite close to 1, and so our classifier is very good at minimizing false negatives (spam which is classified as real) and true negatives (real email which is classified as real).\n",
    "\n",
    "Note that, since we are taking the area under the whole ROC curve, the result is not related to any particular threshold. Therefore, a high AUC does not tell us which is the best threshold to obtain useful classification predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall curve\n",
    "\n",
    "As discussed above, changing the threshold for the predicted probability (above which we classify the email as spam) has an effect on the performance of the algorithm. For example, the true positive rate, or recall, is 0 if we set the threshold as 1, as no email is classified as spam, so it might be a good idea to have a smaller threshold. But having a recall of 1 is not necessarily good, as a model which classifies everything as spam has recall equal to 1, but also very low precision, as there will be a lot of false positives.\n",
    "\n",
    "A good way to illustrate this trade-off between precision and recall is with the precision-recall curve. It can be obtained by importing precision_recall_curve from sklearn.metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a26face48>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve \n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "# create plot\n",
    "plt.plot(precision, recall, label='Precision-recall curve')\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Precision-recall curve')\n",
    "plt.legend(loc=\"lower left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the ROC curve, each point in the plot corresponds to a different threshold. Threshold equal to 0 implies that the recall is 1, whereas threshold equal to 1 implies that the recall is 0, so the threshold varies from 0 to 1 from the top-left to the bottom-right of the plot. Note that the precision starts from roughly 0.7, as there aren’t many false positives (real emails classified as spam).\n",
    "\n",
    "With the precision-recall curve, the closer it is to the top-right corner, the better the algorithm. And hence a larger area under the curve (AUC) indicates that the algorithm has higher recall and higher precision. \n",
    "\n",
    "In this context, the area is known as average precision and can be obtained by importing roc_auc_score from sklearn.metrics,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734360505098615"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, this number is not connected with any particular threshold (we are averaging over all possible thresholds), and so it doesn’t tell us which is the best threshold to consider for useful classification predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at these incorrectly classified messages, you might think does the message's length have something to do with it being a spam/ham.\n",
    "\n",
    "Next, we will examine the our trained Naive Bayes model to calculate the approximate \"spamminess\" of each token to see which word appears more often in spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875    Would you like to see my XXX pics they are so ...\n",
       "4514    Money i have won wining number 946 wot do i do...\n",
       "684     Hi I'm sue. I am 20 years old and work as a la...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "5037    You won't believe it but it's true. It's Incre...\n",
       "3419    LIFE has never been this much fun and great un...\n",
       "4069    TBS/PERSOLVO. been chasing us since Sept for£3...\n",
       "2823    ROMCAPspam Everyone around should be respondin...\n",
       "4256    Block Breaker now comes in deluxe format with ...\n",
       "1893    CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[(y_pred_class == 0) & (y_test == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1206,    6],\n",
       "       [  10,  172]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can calculate the relative \"spamminess\" of each token, we need to avoid dividing by zero and account for the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following:  http://ethen8181.github.io/machine-learning/text_classification/basics/basics.html.  You can watch him doing this tutorial at:  https://www.youtube.com/watch?v=znfy3T9OiAQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
