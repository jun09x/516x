{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have finished watching a video on support vector machines.  This algorithm offers very high accuracy compared to other classifiers. It is used in diverse applications such as face detection, intrusion detection, classification of emails,  and handwriting recognition.  This classifier works by separating data points using a hyperplane with the largest amount of margin.\n",
    "\n",
    "Let's take a look at using SVM to analyze if we can use specific data measurements to improve the diagnosis of breast cancer.  We have a dataset that includes tumors, malignant (cancerous) or benign (non-cancerous), and features obtained from several cell images.\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.  The dataset is hosted [here](http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29) but I have put it also in our Github repository.\n",
    "\n",
    "Briefly:\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Additionally, the mean, standard error and “worst” or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>conc_mean</th>\n",
       "      <th>conc_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>conc_worst</th>\n",
       "      <th>conc_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractral_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  conc_mean  conc_points_mean  ...  \\\n",
       "0          0.11840           0.27760     0.3001           0.14710  ...   \n",
       "1          0.08474           0.07864     0.0869           0.07017  ...   \n",
       "2          0.10960           0.15990     0.1974           0.12790  ...   \n",
       "3          0.14250           0.28390     0.2414           0.10520  ...   \n",
       "4          0.10030           0.13280     0.1980           0.10430  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  conc_worst  conc_points_worst  symmetry_worst  \\\n",
       "0             0.6656      0.7119             0.2654          0.4601   \n",
       "1             0.1866      0.2416             0.1860          0.2750   \n",
       "2             0.4245      0.4504             0.2430          0.3613   \n",
       "3             0.8663      0.6869             0.2575          0.6638   \n",
       "4             0.2050      0.4000             0.1625          0.2364   \n",
       "\n",
       "   fractral_worst  \n",
       "0         0.11890  \n",
       "1         0.08902  \n",
       "2         0.08758  \n",
       "3         0.17300  \n",
       "4         0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('../data/cancer.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x11f6ba110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(dataset, hue = 'diagnosis', vars = ['radius_mean', 'texture_mean', 'area_mean', 'smoothness_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the dataset for SVM algorithms, I'd suggest doing three things:\n",
    "\n",
    "1.  Check for NA values.  Previously, I've pretty much ignored this step but for your own datasets you may want to do so to decide how to deal with them.\n",
    "\n",
    "2.  Decide what data goes into your X and y variables.  \n",
    "\n",
    "3.  Ensure that the label categories are numeric.\n",
    "\n",
    "4.  Create training and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "conc_mean            0\n",
       "conc_points_mean     0\n",
       "symmetry_mean        0\n",
       "fractral_mean        0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "conc_se              0\n",
       "conc_points_se       0\n",
       "symmetry_se          0\n",
       "fractral_se          0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "conc_worst           0\n",
       "conc_points_worst    0\n",
       "symmetry_worst       0\n",
       "fractral_worst       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:, 2:32].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = dataset.iloc[:,1].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You've learned one way of doing this previously in our Naive Bayes tutorial.\n",
    "# Here is another nifty way of converting labels to numerical values.\n",
    "\n",
    "#Encoding categorical data values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21395901,  0.3125461 , -0.14355187, ...,  1.37043754,\n",
       "         1.08911166,  1.53928319],\n",
       "       [-0.26750714,  1.461224  , -0.32955207, ..., -0.84266106,\n",
       "        -0.71577388, -0.88105993],\n",
       "       [-0.03922298, -0.86770223, -0.10463112, ..., -0.505318  ,\n",
       "        -1.20298225, -0.92494342],\n",
       "       ...,\n",
       "       [-0.51270124, -1.69096186, -0.54095317, ..., -0.12632201,\n",
       "         0.33773512, -0.42872244],\n",
       "       [-0.17732081, -2.01395163, -0.17345939, ..., -0.62875108,\n",
       "        -0.29500302, -0.65432858],\n",
       "       [ 1.5305829 , -0.26300709,  1.57961296, ...,  1.6694843 ,\n",
       "         1.18085869,  0.48889253]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "#Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [ 3, 50]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        91\n",
      "           1       0.94      0.96      0.95        52\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "print(classification_report(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the success of this model for predicting malignant and benign tumors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix and the accuracy score we can see that, the svm model have a very high predicting accuracy score which is 96.5%. For 100 sample tested 96.5 sample will be correctly classified. From the classification report we can see that the precision for 0 and 1 is very high and close to each other, which mean the model is well balanced and the accuracy is high. The precision and recall vaule is very close, means the model returned the most relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptual Review Questions:\n",
    "1.  What is is a hyperplane in SVM and how is it used?\n",
    "2.  What are two tuning parameters that can be used for SVM and how do they impact the model in terms of overfitting?\n",
    "3.  What are the pros and cons of SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The hyperplane in SVM means the maximaize margin between the two classes. The hpyerplan helps to make a deicision boundry to separate the two different classes. \n",
    "2. The first parameters is c, the c parameters tells the svm model how much tolerance for misclassification. The large value of c will choose a small margin of hyperplane. The second parameters is the kernel used for svm model, the kernel for svm model should be changed based on the size of the dataset and the ditribution of the data to avoid the overfitting problems.\n",
    "3. The pros for svm: (1) Effective in high dimensional spaces, even for the cases where number of dimensions is greater than the number of samples. (2) It is also memory efficient, since it use a subset in the decision function. (3)The model could use different Kernel functions. The cons for svm: (1) Need to choose different kernel to avoid over fitting situation when the sample feature is much larger than the sample size. (2) SVM will not provide the probability estimates directly, the probability estimates is calculated based on the expensive five-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a202d4d68>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(X_train[1,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
